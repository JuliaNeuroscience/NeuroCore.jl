var documenterSearchIndex = {"docs":
[{"location":"introduction_properties/#Introduction-to-Properties-1","page":"Introduction to Properties","title":"Introduction to Properties","text":"","category":"section"},{"location":"introduction_properties/#What-are-properties?-1","page":"Introduction to Properties","title":"What are properties?","text":"","category":"section"},{"location":"introduction_properties/#","page":"Introduction to Properties","title":"Introduction to Properties","text":"NeuroCore uses properties (as defined in FieldProperties.jl) for the majority of its API. This means that most properties in this package have a way of retrieving, setting, and enforcing type stability for each property (anything defined using the macro @defprop). For example, epoch_length(x)'s default behavior is to call getproperty(x, :epoch_length) and epoch_length!(x, val)'s default behavior is to call setproperty!(x, :epoch_length, val). Therefore, any given type can use this method by simply defining a field named epoch_length. Details on the order of calls, enforcing certain return types, and documenting properties is further defined in the FieldProperties.jl) documentation.","category":"page"},{"location":"introduction_properties/#Why-use-properties?-1","page":"Introduction to Properties","title":"Why use properties?","text":"","category":"section"},{"location":"introduction_properties/#","page":"Introduction to Properties","title":"Introduction to Properties","text":"Instead of pursuing a single data structure that everyone else conforms to, NeuroCore allows for any data structure as long as the return type of a given method is consistent. This solution is much more tenable than enforcing a limited set of structures, which would require continually changes to structures in order to meet the needs of an evolving field. For example, there are many neurophysiology file formats. Numerous efforts to form a universal standard have yet to be fully adopted in the neuroscience community. Using NeuroCore allows users to have a consistent API right now and developers the flexibility of optimizing hardware and file formats over time. Therefore, NeuroCore only attempts to enforce:","category":"page"},{"location":"introduction_properties/#","page":"Introduction to Properties","title":"Introduction to Properties","text":"Types for core data (see NeuroCore Types)\nTypes for individual pieces of metadata (aka properties)","category":"page"},{"location":"introduction_properties/#","page":"Introduction to Properties","title":"Introduction to Properties","text":"This leaves the organization of metadata up to the discretion of package authors. Although there are a number of metadata types provided, they mainly serve as a convenient way to store a number of related properties and do not represent a strict guideline on how to organize metadata.","category":"page"},{"location":"introduction_properties/#Why-*these*-properties?-1","page":"Introduction to Properties","title":"Why these properties?","text":"","category":"section"},{"location":"introduction_properties/#","page":"Introduction to Properties","title":"Introduction to Properties","text":"The majority of properties were defined and documented using the definitions provided from the Brain Imaging Data Structures (BIDS) standard. This allowed the use of nomenclature that had already been agreed upon by individuals from multiple fields and has already been adopted by a significant portion of the neuroscience community. Similar to the BIDS standard, this package is not restricted to the topic of brain imaging. Unlike BIDS, this package does not focus on neuroscience related ontology outside of its pragmatic application to computational tools.","category":"page"},{"location":"anatomical_api/#Anatomical-API-1","page":"Anatomical API","title":"Anatomical API","text":"","category":"section"},{"location":"anatomical_api/#","page":"Anatomical API","title":"Anatomical API","text":"NeuroCore places a strong emphasis on arrays with named dimensions. This allows the use of well established interfaces for arrays across the julia ecosystem while still providing meaningful information that may be specific to the type of data being worked with.","category":"page"},{"location":"anatomical_api/#References-1","page":"Anatomical API","title":"References","text":"","category":"section"},{"location":"anatomical_api/#","page":"Anatomical API","title":"Anatomical API","text":"Modules = [NeuroCore.AnatomicalAPI]\nOrder   = [:function, :type]","category":"page"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.axial_axis-Tuple{Any,Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.axial_axis","text":"axial_axis(x, size[; first_pad=nothing, last_pad=nothing, stride=nothing, dilation=nothing])\n\nReturns an AxisIterator along the axial axis.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.axial_axis-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.axial_axis","text":"axial_axis(x)\n\nReturns the axis corresponding to the axial dimension.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.axial_axis_type-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.axial_axis_type","text":"axial_axis_type(x)\n\nReturns the key type corresponding to the axial axis.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.axial_indices-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.axial_indices","text":"axial_indices(x)\n\nReturns the indices corresponding to the axial axis\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.axial_keys-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.axial_keys","text":"axial_keys(x)\n\nReturns the keys corresponding to the axial axis\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.axialdim-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.axialdim","text":"axialdim(x) -> Int\n\nReturns the dimension corresponding to axial.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.coronal_axis-Tuple{Any,Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.coronal_axis","text":"coronal_axis(x, size[; first_pad=nothing, last_pad=nothing, stride=nothing, dilation=nothing])\n\nReturns an AxisIterator along the coronal axis.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.coronal_axis-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.coronal_axis","text":"coronal_axis(x)\n\nReturns the axis corresponding to the coronal dimension.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.coronal_axis_type-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.coronal_axis_type","text":"coronal_axis_type(x)\n\nReturns the key type corresponding to the coronal axis.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.coronal_indices-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.coronal_indices","text":"coronal_indices(x)\n\nReturns the indices corresponding to the coronal axis\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.coronal_keys-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.coronal_keys","text":"coronal_keys(x)\n\nReturns the keys corresponding to the coronal axis\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.coronaldim-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.coronaldim","text":"coronaldim(x) -> Int\n\nReturns the dimension corresponding to coronal.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.each_axial-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.each_axial","text":"each_axial(x)\n\nCreate a generator that iterates over the axial dimensions A, returning views that select all the data from the other dimensions in A.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.each_coronal-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.each_coronal","text":"each_coronal(x)\n\nCreate a generator that iterates over the coronal dimensions A, returning views that select all the data from the other dimensions in A.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.each_sagittal-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.each_sagittal","text":"each_sagittal(x)\n\nCreate a generator that iterates over the sagittal dimensions A, returning views that select all the data from the other dimensions in A.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.has_axialdim-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.has_axialdim","text":"has_axialdim(x) -> Bool\n\nReturns true if x has a dimension corresponding to axial.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.has_coronaldim-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.has_coronaldim","text":"has_coronaldim(x) -> Bool\n\nReturns true if x has a dimension corresponding to coronal.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.has_sagittaldim-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.has_sagittaldim","text":"has_sagittaldim(x) -> Bool\n\nReturns true if x has a dimension corresponding to sagittal.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_anatomical-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_anatomical","text":"is_anatomical(x) -> Bool\n\nReturns true if T represents anatomical data.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_axial-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_axial","text":"is_axial(x) -> Bool\n\nReturns true if x represent the axial orientation.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_coronal-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_coronal","text":"is_coronal(x) -> Bool\n\nReturns true if x represent the coronal orientation.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_neurologic-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_neurologic","text":"is_neurologic(x) -> Bool\n\nTest to see if x is in neurological orientation.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_radiologic-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_radiologic","text":"is_radiologic(x) -> Bool\n\nTest to see if x is in radiological orientation.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_sagittal-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_sagittal","text":"is_sagittal(x) -> Bool\n\nReturns true if x represent the sagittal orientation.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.naxial-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.naxial","text":"naxial(x) -> Int\n\nReturns the size along the dimension corresponding to the axial.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.ncoronal-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.ncoronal","text":"ncoronal(x) -> Int\n\nReturns the size along the dimension corresponding to the coronal.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.nsagittal-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.nsagittal","text":"nsagittal(x) -> Int\n\nReturns the size along the dimension corresponding to the sagittal.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.sagittal_axis-Tuple{Any,Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.sagittal_axis","text":"sagittal_axis(x, size[; first_pad=nothing, last_pad=nothing, stride=nothing, dilation=nothing])\n\nReturns an AxisIterator along the sagittal axis.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.sagittal_axis-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.sagittal_axis","text":"sagittal_axis(x)\n\nReturns the axis corresponding to the sagittal dimension.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.sagittal_axis_type-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.sagittal_axis_type","text":"sagittal_axis_type(x)\n\nReturns the key type corresponding to the sagittal axis.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.sagittal_indices-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.sagittal_indices","text":"sagittal_indices(x)\n\nReturns the indices corresponding to the sagittal axis\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.sagittal_keys-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.sagittal_keys","text":"sagittal_keys(x)\n\nReturns the keys corresponding to the sagittal axis\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.sagittaldim-Tuple{Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.sagittaldim","text":"sagittaldim(x) -> Int\n\nReturns the dimension corresponding to sagittal.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.EncodingDirection","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.EncodingDirection","text":"EncodingDirection\n\nPossible values: ipos, jpos, kpos, ineg,jneg,kneg(the axis of the NIfTI data along which slices were acquired, and the direction in which SliceTiming is defined with respect to).ipos,jpos,kposidentifiers correspond to the first, second and third axis of the data in the NIfTI file.*neg` indicates that the contents of SliceTiming are defined in reverse order - that is, the first entry corresponds to the slice with the largest index, and the final entry corresponds to slice index zero. \n\n\n\n\n\n","category":"type"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_anterior-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_anterior","text":"is_anterior(x) -> Bool\n\nReturns true if x represent the anterior position.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_channel-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_channel","text":"is_channel(::T) -> Bool\n\nReturns true if T represents a gyrus.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_cortical-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_cortical","text":"is_cortical(::T) -> Bool\n\nReturns true if T represents a cortical region.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_csf-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_csf","text":"is_csf(::T) -> Bool\n\nReturns true if T represents a region of corticospinal fluid (CSF).\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_electrophysiology-Union{Tuple{T}, Tuple{T}} where T","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_electrophysiology","text":"is_electrophysiology(::T) -> Bool\n\nReturns true if T represents electrophysiology data.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_gyrus-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_gyrus","text":"is_gyrus(::T) -> Bool\n\nReturns true if T represents a gyrus.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_inferior-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_inferior","text":"is_inferior(x) -> Bool\n\nReturns true if x represent the inferior position.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_left-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_left","text":"is_left(x) -> Bool\n\nReturns true if x represent the left position.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_posterior-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_posterior","text":"is_posterior(x) -> Bool\n\nReturns true if x represent the posterior position.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_right-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_right","text":"is_right(x) -> Bool\n\nReturns true if x represent the right position.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_sulcus-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_sulcus","text":"is_sulcus(::T) -> Bool\n\nReturns true if T represents a gyrus.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_superior-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_superior","text":"is_superior(x) -> Bool\n\nReturns true if x represent the superior position.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.is_white_matter-Tuple{Symbol}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.is_white_matter","text":"is_white_matter(::T) -> Bool\n\nReturns true if T represents white matter.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.select_axial-Tuple{Any,Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.select_axial","text":"select_axial(x, i)\n\nReturn a view of all the data of x where the index for the axial dimension equals i.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.select_coronal-Tuple{Any,Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.select_coronal","text":"select_coronal(x, i)\n\nReturn a view of all the data of x where the index for the coronal dimension equals i.\n\n\n\n\n\n","category":"method"},{"location":"anatomical_api/#NeuroCore.AnatomicalAPI.select_sagittal-Tuple{Any,Any}","page":"Anatomical API","title":"NeuroCore.AnatomicalAPI.select_sagittal","text":"select_sagittal(x, i)\n\nReturn a view of all the data of x where the index for the sagittal dimension equals i.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#Color-Channels-1","page":"Color Channels","title":"Color Channels","text":"","category":"section"},{"location":"color_channels/#References-1","page":"Color Channels","title":"References","text":"","category":"section"},{"location":"color_channels/#","page":"Color Channels","title":"Color Channels","text":"Modules = [NeuroCore.ColorChannels]\nOrder   = [:function, :type]","category":"page"},{"location":"color_channels/#NeuroCore.ColorChannels.channel_axis-Tuple{Any,Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.channel_axis","text":"channel_axis(x, size[; first_pad=nothing, last_pad=nothing, stride=nothing, dilation=nothing])\n\nReturns an AxisIterator along the channel axis.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.channel_axis-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.channel_axis","text":"channel_axis(x)\n\nReturns the axis corresponding to the channel dimension.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.channel_axis_type-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.channel_axis_type","text":"channel_axis_type(x)\n\nReturns the key type corresponding to the channel axis.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.channel_indices-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.channel_indices","text":"channel_indices(x)\n\nReturns the indices corresponding to the channel axis\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.channel_keys-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.channel_keys","text":"channel_keys(x)\n\nReturns the keys corresponding to the channel axis\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.channel_view-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T<:Number","page":"Color Channels","title":"NeuroCore.ColorChannels.channel_view","text":"channel_view(A)\n\nreturns a view of A, splitting out (if necessary) the color channels of A into a new first dimension.\n\nOf relevance for types like RGB and BGR, the channels of the returned array will be in constructor-argument order, not memory order (see reinterpretc if you want to use memory order).\n\nExample\n\n```julia img = rand(RGB{N0f8}, 10, 10) A = channel_view(img)   # a 3×10×10 array\n\nSee also: color_view\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.channeldim-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.channeldim","text":"channeldim(x) -> Int\n\nReturns the dimension corresponding to channel.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.clamp01!-Tuple{AbstractArray}","page":"Color Channels","title":"NeuroCore.ColorChannels.clamp01!","text":"clamp01!(array::AbstractArray)\n\nRestrict values in array to [0, 1], in-place. See also clamp01.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.clamp01-Tuple{Union{FixedPointNumbers.Normed{UInt16,16}, FixedPointNumbers.Normed{UInt8,8}}}","page":"Color Channels","title":"NeuroCore.ColorChannels.clamp01","text":"clamp01(x) -> y\n\nProduce a value y that lies between 0 and 1, and equal to x when x is already in this range. Equivalent to clamp(x, 0, 1) for numeric values. For colors, this function is applied to each color channel separately.\n\nSee also: clamp01!, clamp01nan.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.clamp01nan!-Tuple{AbstractArray{T,N} where N where T<:Union{Number, ColorTypes.Colorant}}","page":"Color Channels","title":"NeuroCore.ColorChannels.clamp01nan!","text":"clamp01nan!(array::AbstractArray)\n\nSimilar to clamp01!, except that any NaN values are changed to 0.\n\nSee also: clamp01!, clamp01nan\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.clamp01nan-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.clamp01nan","text":"clamp01nan(x) -> y\n\nSimilar to clamp01, except that any NaN values are changed to 0.\n\nSee also: clamp01nan!, clamp01.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.color_signed-Union{Tuple{C}, Tuple{C,C,C}} where C<:ColorTypes.Colorant","page":"Color Channels","title":"NeuroCore.ColorChannels.color_signed","text":"color_signed()\ncolor_signed(colorneg, colorpos) -> f\ncolor_signed(colorneg, colorcenter, colorpos) -> f\n\nDefine a function that maps negative values (in the range [-1,0]) to the linear colormap between colorneg and colorcenter, and positive values (in the range [0,1]) to the linear colormap between colorcenter and colorpos.\n\nThe default colors are:\n\ncolorcenter: white\ncolorneg: green1\ncolorpos: magenta\n\nSee also: scale_signed.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.color_view-Union{Tuple{C}, Tuple{Type{C},Any,Any,Vararg{Any,N} where N}} where C<:ColorTypes.Colorant","page":"Color Channels","title":"NeuroCore.ColorChannels.color_view","text":"color_view(C, gray1, gray2, ...) -> imgC\n\nCombine numeric/grayscale images gray1, gray2, etc., into the separate color channels of an array imgC with element type C<:Colorant.\n\nAs a convenience, the constant zeroarray fills in an array of matched size with all zeros.\n\nExample\n\nimgC = color_view(RGB, r, zeroarray, b)\n\ncreates an image with r in the red chanel, b in the blue channel, and nothing in the green channel.\n\nSee also: StackedView.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.color_view-Union{Tuple{T}, Tuple{C}, Tuple{Type{C},AbstractArray{T,N} where N}} where T<:Number where C<:ColorTypes.Colorant","page":"Color Channels","title":"NeuroCore.ColorChannels.color_view","text":"color_view(C, A)\n\nreturns a view of the numeric array A, interpreting successive elements of A as if they were channels of Colorant C.\n\nOf relevance for types like RGB and BGR, the elements of A are interpreted in constructor-argument order, not memory order (see reinterpretc if you want to use memory order).\n\nExample\n\nA = rand(3, 10, 10)\nimg = color_view(RGB, A)\n\nSee also: channel_view\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.float32","page":"Color Channels","title":"NeuroCore.ColorChannels.float32","text":"float32.(img)\n\nconverts the raw storage type of img to Float32, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.float64","page":"Color Channels","title":"NeuroCore.ColorChannels.float64","text":"float64.(img)\n\nconverts the raw storage type of img to Float64, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.n0f16","page":"Color Channels","title":"NeuroCore.ColorChannels.n0f16","text":"n0f16.(img)\n\nconverts the raw storage type of img to N0f16, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.n0f8","page":"Color Channels","title":"NeuroCore.ColorChannels.n0f8","text":"n0f8.(img)\n\nconverts the raw storage type of img to N0f8, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.n2f14","page":"Color Channels","title":"NeuroCore.ColorChannels.n2f14","text":"n2f14.(img)\n\nconverts the raw storage type of img to N2f14, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.n4f12","page":"Color Channels","title":"NeuroCore.ColorChannels.n4f12","text":"n4f12.(img)\n\nconverts the raw storage type of img to N4f12, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.n6f10","page":"Color Channels","title":"NeuroCore.ColorChannels.n6f10","text":"n6f10.(img)\n\nconverts the raw storage type of img to N6f10, without changing the color space.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.nchannel-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.nchannel","text":"nchannel(x) -> Int\n\nReturns the size along the dimension corresponding to the channel.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.normed_view-Union{Tuple{S}, Tuple{T}, Tuple{Type{T},AbstractArray{S,N} where N}} where S<:Unsigned where T<:FixedPointNumbers.FixedPoint","page":"Color Channels","title":"NeuroCore.ColorChannels.normed_view","text":"normed_view([T], img::AbstractArray{Unsigned})\n\nreturns a \"view\" of img where the values are interpreted in terms of Normed number types. For example, if img is an Array{UInt8}, the view will act like an Array{N0f8}.  Supply T if the element type of img is UInt16, to specify whether you want a N6f10, N4f12, N2f14, or N0f16 result.\n\nSee also: raw_view\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.raw_view-Union{Tuple{AbstractArray{T,N} where N}, Tuple{T}} where T<:FixedPointNumbers.FixedPoint","page":"Color Channels","title":"NeuroCore.ColorChannels.raw_view","text":"raw_view(img::AbstractArray{FixedPoint})\n\nreturns a \"view\" of img where the values are interpreted in terms of their raw underlying storage. For example, if img is an Array{N0f8}, the view will act like an Array{UInt8}.\n\nSee also: normed_view\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.scale_minmax-Union{Tuple{T}, Tuple{T,T}} where T","page":"Color Channels","title":"NeuroCore.ColorChannels.scale_minmax","text":"scale_minmax(min, max) -> f\nscale_minmax(T, min, max) -> f\n\nReturn a function f which maps values less than or equal to min to 0, values greater than or equal to max to 1, and uses a linear scale in between. min and max should be real values.\n\nOptionally specify the return type T. If T is a colorant (e.g., RGB), then scaling is applied to each color channel.\n\nExamples\n\nExample 1\n\njulia> f = scale_minmax(-10, 10)\n(::#9) (generic function with 1 method)\n\njulia> f(10)\n1.0\n\njulia> f(-10)\n0.0\n\njulia> f(5)\n0.75\n\nExample 2\n\njulia> c = RGB(255.0,128.0,0.0)\nRGB{Float64}(255.0,128.0,0.0)\n\njulia> f = scale_minmax(RGB, 0, 255)\n(::#13) (generic function with 1 method)\n\njulia> f(c)\nRGB{Float64}(1.0,0.5019607843137255,0.0)\n\nSee also: take_map.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.scale_signed-Tuple{Real}","page":"Color Channels","title":"NeuroCore.ColorChannels.scale_signed","text":"scale_signed(maxabs) -> f\n\nReturn a function f which scales values in the range [-maxabs, maxabs] (clamping values that lie outside this range) to the range [-1, 1].\n\nSee also: color_signed.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.scale_signed-Union{Tuple{T}, Tuple{T,T,T}} where T<:Real","page":"Color Channels","title":"NeuroCore.ColorChannels.scale_signed","text":"scale_signed(min, center, max) -> f\n\nReturn a function f which scales values in the range [min, center] to [-1,0] and [center,max] to [0,1]. Values smaller than min/max get clamped to min/max, respectively.\n\nSee also: color_signed.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.select_channel-Tuple{Any,Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.select_channel","text":"select_channel(x, i)\n\nReturn a view of all the data of x where the index for the channel dimension equals i.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.take_map","page":"Color Channels","title":"NeuroCore.ColorChannels.take_map","text":"take_map(f, A) -> fnew\ntake_map(f, T, A) -> fnew\n\nGiven a value-mapping function f and an array A, return a \"concrete\" mapping function fnew. When applied to elements of A, fnew should return valid values for storage or display, for example in the range from 0 to 1 (for grayscale) or valid colorants. fnew may be adapted to the actual values present in A, and may not produce valid values for any inputs not in A.\n\nOptionally one can specify the output type T that fnew should produce.\n\nExample:\n\njulia> A = [0, 1, 1000];\n\njulia> f = take_map(scale_minmax, A)\n(::#7) (generic function with 1 method)\n\njulia> f.(A)\n3-element Array{Float64,1}:\n 0.0\n 0.001\n 1.0\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.StackedView","page":"Color Channels","title":"NeuroCore.ColorChannels.StackedView","text":"StackedView(B, C, ...) -> A\n\nPresent arrays B, C, etc, as if they are separate channels along the first dimension of A. In particular,\n\nB == A[1,:,:...]\nC == A[2,:,:...]\n\nand so on. Combined with color_view, this allows one to combine two or more grayscale images into a single color image.\n\nSee also: color_view.\n\n\n\n\n\n","category":"type"},{"location":"color_channels/#Base.float-Tuple{ColorTypes.Colorant}","page":"Color Channels","title":"Base.float","text":"float(x::Colorant)\nfloat(T::Type{<:Colorant})\n\nconvert the storage type of pixel x to a floating point data type while preserving the Colorant information.\n\nIf the input is Type T, then it is equivalent to floattype.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.each_channel-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.each_channel","text":"each_channel(x)\n\nCreate a generator that iterates over the channel dimensions A, returning views that select all the data from the other dimensions in A.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.getchannels","page":"Color Channels","title":"NeuroCore.ColorChannels.getchannels","text":"getchannels(P, C::Type, I)\n\nGet a tuple of all channels needed to construct a Colorant of type C from an P::AbstractArray{<:Number}.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.has_channeldim-Tuple{Any}","page":"Color Channels","title":"NeuroCore.ColorChannels.has_channeldim","text":"has_channeldim(x) -> Bool\n\nReturns true if x has a dimension corresponding to channel.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.setchannel-Union{Tuple{T}, Tuple{ColorTypes.Colorant{T,1},Any,Int64}} where T","page":"Color Channels","title":"NeuroCore.ColorChannels.setchannel","text":"setchannel(c, val, idx)\n\nEquivalent to:\n\ncc = copy(c)\ncc[idx] = val\ncc\n\nfor immutable colors. idx is interpreted in the sense of constructor arguments, so setchannel(c, 0.5, 1) would set red color channel for any c::AbstractRGB, even if red isn't the first field in the type.\n\n\n\n\n\n","category":"method"},{"location":"color_channels/#NeuroCore.ColorChannels.setchannels!","page":"Color Channels","title":"NeuroCore.ColorChannels.setchannels!","text":"setchannels!(P, val, I)\n\nFor a color val, distribute its channels along P[:, I...] for P::AbstractArray{<:Number}.\n\n\n\n\n\n","category":"function"},{"location":"color_channels/#NeuroCore.ColorChannels.ColorChanPerm","page":"Color Channels","title":"NeuroCore.ColorChannels.ColorChanPerm","text":"ColorChanPerm(perm)\n\nConstruct a reordering permutation for the color channel. This handles swaps between memory layout and constructor argument order for AbstractRGB and various AlphaChannel and ChannelAlpha color types.\n\n\n\n\n\n","category":"type"},{"location":"electrophysiology/#Electrophysiology-1","page":"Electrophysiology","title":"Electrophysiology","text":"","category":"section"},{"location":"electrophysiology/#","page":"Electrophysiology","title":"Electrophysiology","text":"NeuroCore.nchannels\nNeuroCore.high_cutoff\nNeuroCore.low_cutoff\nNeuroCore.notch_filter\nNeuroCore.electrode_groups\nNeuroCore.ground_electrode\nNeuroCore.placement_scheme\nNeuroCore.power_line_frequency\nNeuroCore.dewar_position\nNeuroCore.electrical_stimulation\nNeuroCore.electrical_stimulation_parameters\nNeuroCore.epoch_length","category":"page"},{"location":"plots/#Plots-1","page":"Plots","title":"Plots","text":"","category":"section"},{"location":"plots/#","page":"Plots","title":"Plots","text":"Coming soon","category":"page"},{"location":"properties/#NeuroCore-Properties-1","page":"NeuroCore Properties","title":"NeuroCore Properties","text":"","category":"section"},{"location":"properties/#","page":"NeuroCore Properties","title":"NeuroCore Properties","text":"NeurCore uses the concept of properties from FieldProperties.jl to create an API that is flexible for developers but consistent for users. We'll use the onset property to demonstrate this.","category":"page"},{"location":"properties/#","page":"NeuroCore Properties","title":"NeuroCore Properties","text":"julia> using NeuroCore\n","category":"page"},{"location":"imaging_metadata/#Imaging-Metadata-1","page":"Imaging","title":"Imaging Metadata","text":"","category":"section"},{"location":"imaging_metadata/#Sequence-Metadata-1","page":"Imaging","title":"Sequence Metadata","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.SequenceMetadata","category":"page"},{"location":"imaging_metadata/#Properties-1","page":"Imaging","title":"Properties","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.nonlinear_gradient_correction\nNeuroCore.pulse_sequence\nNeuroCore.pulse_sequence_details\nNeuroCore.scanning_sequence\nNeuroCore.sequence_name\nNeuroCore.sequence_variant","category":"page"},{"location":"imaging_metadata/#Encoding-Direction-1","page":"Imaging","title":"Encoding Direction","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.EncodingDirectionMetadata","category":"page"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.EncodingDirectionMetadata","page":"Imaging","title":"NeuroCore.NeuroMetadata.EncodingDirectionMetadata","text":"EncodingDirectionMetadata\n\nMetadata structure for general MRI sequence information.\n\nSupported Properties\n\nfreqdim: Which spatial dimension (1, 2, or 3) corresponds to phase acquisition.\nphasedim: Which spatial dimension (1, 2, or 3) corresponds to phase acquisition.\nslicedim: Which dimension slices where acquired at throughout MRI acquisition.\nslice_start: Which slice corresponds to the first slice acquired during MRI acquisition (i.e. not padded slices).\nslice_end: Which slice corresponds to the last slice acquired during MRI acquisition (i.e. not padded slices).\nslice_duration: Time to acquire one slice\nslice_encoding_direction: Values ending in \"neg\" indicate that the contents of slicetiming are defined in reverse order (the first entry corresponds to the slice with the largest index, and the final entry corresponds to slice index zero. When present, the axis defined by slice*encodingneeds to be consistent with theslicedim field in the NIfTI header. When absent, the entries in slice_timing must be in the order of increasing slice index as defined by the NIfTI header.\nphase_encoding_direction: The phase encoding direction is defined as the direction along which phase was modulated which may result in visible distortions. Note that this is not the same as the DICOM term \"inplanephaseencodingdirection\" which can have \"ROW\" or \"COL\" values. This parameter is REQUIRED if corresponding fieldmap data is present or when using multiple runs with different phase encoding directions (which can be later used for field inhomogeneity correction).\n\nExamples\n\njulia> using NeuroCore\n\njulia> using NeuroCore.NeuroMetadata\n\njulia> m = EncodingDirectionMetadata(1, 2, 3, 4, 5, 6)\nEncodingDirectionMetadata(1, 2, 3, 4, 5, 6.0)\n\njulia> m.slice_encoding_direction\nkpos::EncodingDirection = 3\n\njulia> m.slice_encoding_direction == slice_encoding_direction(m)\ntrue\n\njulia> m.phase_encoding_direction\njpos::EncodingDirection = 2\n\njulia> m.phase_encoding_direction == phase_encoding_direction(m)\ntrue\n\njulia> m.freqdim\n1\n\njulia> m.freqdim == freqdim(m)\ntrue\n\njulia> m.phasedim\n2\n\njulia> m.phasedim == phasedim(m)\ntrue\n\njulia> m.slicedim\n3\n\njulia> m.slicedim == slicedim(m)\ntrue\n\njulia> m.slice_start\n4\n\njulia> m.slice_start == slice_start(m)\ntrue\n\njulia> m.slice_end\n5\n\njulia> m.slice_end == slice_end(m)\ntrue\n\njulia> m.slice_duration\n6.0\n\njulia> m.slice_duration == slice_duration(m)\ntrue\n\n\n\n\n\n","category":"type"},{"location":"imaging_metadata/#Properties-2","page":"Imaging","title":"Properties","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.EncodingDirection\nNeuroCore.phase_encoding_direction\nNeuroCore.slice_encoding_direction\nNeuroCore.freqdim\nNeuroCore.phasedim\nNeuroCore.slicedim\nNeuroCore.slice_start\nNeuroCore.slice_end\nNeuroCore.slice_duration","category":"page"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.phase_encoding_direction","page":"Imaging","title":"NeuroCore.NeuroMetadata.phase_encoding_direction","text":"phase_encoding_direction(x) -> EncodingDirection\n\nThe phase encoding direction is defined as the direction along which phase was modulated which may result in visible distortions. Note that this is not the same as the DICOM term \"inplanephaseencodingdirection\" which can have \"ROW\" or \"COL\" values. This parameter is REQUIRED if corresponding fieldmap data is present or when using multiple runs with different phase encoding directions (which can be later used for field inhomogeneity correction).\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.slice_encoding_direction","page":"Imaging","title":"NeuroCore.NeuroMetadata.slice_encoding_direction","text":"slice_encoding_direction(x) -> EncodingDirection\n\nValues ending in \"*neg\" indicate that the contents of slicetiming are defined in reverse order (the first entry corresponds to the slice with the largest index, and the final entry corresponds to slice index zero. When present, the axis defined by `sliceencodingneeds to be consistent with theslicedim` field in the NIfTI header. When absent, the entries in slice_timing must be in the order of increasing slice index as defined by the NIfTI header.\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.freqdim","page":"Imaging","title":"NeuroCore.NeuroMetadata.freqdim","text":"freqdim(x)\nfreqdim!(x, val)\n\nWhich spatial dimension (1, 2, or 3) corresponds to phase acquisition.\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.phasedim","page":"Imaging","title":"NeuroCore.NeuroMetadata.phasedim","text":"phasedim(x)\nphasedim!(x, val)\n\nWhich spatial dimension (1, 2, or 3) corresponds to phase acquisition.\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.slicedim","page":"Imaging","title":"NeuroCore.NeuroMetadata.slicedim","text":"slicedim(x)\nslicedim!(x, val)\n\nWhich dimension slices where acquired at throughout MRI acquisition.\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.slice_start","page":"Imaging","title":"NeuroCore.NeuroMetadata.slice_start","text":"slice_start(x)\nslice_start!(x, val)\n\nWhich slice corresponds to the first slice acquired during MRI acquisition (i.e. not padded slices).\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.slice_end","page":"Imaging","title":"NeuroCore.NeuroMetadata.slice_end","text":"slice_end(x)\nslice_end!(x, val)\n\nWhich slice corresponds to the last slice acquired during MRI acquisition (i.e. not padded slices).\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#NeuroCore.NeuroMetadata.slice_duration","page":"Imaging","title":"NeuroCore.NeuroMetadata.slice_duration","text":"slice_duration(x)\nslice_duration!(x, val)\n\nTime to acquire one slice\n\n\n\n\n\n\n\n","category":"function"},{"location":"imaging_metadata/#Spatial-Encoding-1","page":"Imaging","title":"Spatial Encoding","text":"","category":"section"},{"location":"imaging_metadata/#Properties-3","page":"Imaging","title":"Properties","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.nshots\nNeuroCore.effective_echo_spacing\nNeuroCore.parallel_acquisition_technique\nNeuroCore.parallel_reduction_factor_in_plane\nNeuroCore.partial_fourier\nNeuroCore.partial_fourier_direction\nNeuroCore.total_readout_time","category":"page"},{"location":"imaging_metadata/#Magentization-Transfer-1","page":"Imaging","title":"Magentization Transfer","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.MagnetizationTransferMetadata","category":"page"},{"location":"imaging_metadata/#Properties-4","page":"Imaging","title":"Properties","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.mt_state\nNeuroCore.mt_offset_frequency\nNeuroCore.mt_pulse_bandwidth\nNeuroCore.mt_npulses\nNeuroCore.mt_pulse_shape\nNeuroCore.mt_pulse_duration","category":"page"},{"location":"imaging_metadata/#Spoiling-1","page":"Imaging","title":"Spoiling","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.SpoilingMetadata","category":"page"},{"location":"imaging_metadata/#Properties-5","page":"Imaging","title":"Properties","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.spoiling_state\nNeuroCore.spoiling_type\nNeuroCore.spoiling_gradient_moment\nNeuroCore.spoiling_gradient_duration","category":"page"},{"location":"imaging_metadata/#Time-1","page":"Imaging","title":"Time","text":"","category":"section"},{"location":"imaging_metadata/#","page":"Imaging","title":"Imaging","text":"NeuroCore.echo_time\nNeuroCore.inversion_time\nNeuroCore.slice_timing\nNeuroCore.dwell_time\nNeuroCore.delay_time\nNeuroCore.acquisition_duration\nNeuroCore.volume_timing\nNeuroCore.repetition_time","category":"page"},{"location":"spatial_api/#Spatial-API-1","page":"Spatial API","title":"Spatial API","text":"","category":"section"},{"location":"spatial_api/#References-1","page":"Spatial API","title":"References","text":"","category":"section"},{"location":"spatial_api/#","page":"Spatial API","title":"Spatial API","text":"Modules = [NeuroCore.SpatialAPI]\nOrder   = [:function, :type]","category":"page"},{"location":"spatial_api/#NeuroCore.SpatialAPI.pixel_spacing-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.pixel_spacing","text":"pixel_spacing(x)\n\nReturn a tuple representing the separation between adjacent pixels along each axis of the image. Derived from the step size of each element of spatial_keys.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.sdims-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.sdims","text":"sdims(x)\n\nReturn the number of spatial dimensions in the image. Defaults to the same as ndims, but with NamedDimsArray you can specify that some dimensions correspond to other quantities (e.g., time) and thus not included by sdims.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_axes-Tuple{Any,Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_axes","text":"spatial_axes(x, sz; kwargs...)\n\nReturns an AxesIterator along the spatial axes.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_axes-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_axes","text":"spatial_axes(x) -> Tuple\n\nReturns a tuple of each axis corresponding to a spatial dimensions.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_directions-Tuple{AbstractArray}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_directions","text":"spatial_directions(img) -> (axis1, axis2, ...)\n\nReturn a tuple-of-tuples, each axis[i] representing the displacement vector between adjacent pixels along spatial axis i of the image array, relative to some external coordinate system (\"physical coordinates\").\n\nBy default this is computed from pixel_spacing, but you can set this manually using ImagesMeta.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_indices-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_indices","text":"spatial_indices(x)\n\nReturn a tuple with the indices of the spatial dimensions of the image. Defaults to the same as indices, but using NamedDimsArray you can mark some axes as being non-spatial.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_keys-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_keys","text":"spatial_keys(x)\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_order-Union{Tuple{T}, Tuple{T}} where T","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_order","text":"spatial_order(x) -> Tuple{Vararg{Symbol}}\n\nReturns the dimnames of x that correspond to spatial dimensions.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_size-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_size","text":"spatial_size(x) -> Tuple{Vararg{Int}}\n\nReturn a tuple listing the sizes of the spatial dimensions of the image.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatialdims-Union{Tuple{T}, Tuple{T}} where T","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatialdims","text":"spatialdims(x) -> Tuple{Vararg{Int}}\n\nReturn a tuple listing the spatial dimensions of img. Note that a better strategy may be to use ImagesAxes and take slices along the time axis.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.affine_map-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.affine_map","text":"affine_map(x) -> AffineMap\n\nReturns and affine map. By default using spatial_directions and pixel_spacing are used to constuct the mapping.\n\n\n\n\n\n","category":"method"},{"location":"spatial_api/#NeuroCore.SpatialAPI.spatial_offset-Tuple{Any}","page":"Spatial API","title":"NeuroCore.SpatialAPI.spatial_offset","text":"spatial_offset(x)\n\nThe offset of each dimension (i.e., where each spatial axis starts).\n\n\n\n\n\n","category":"method"},{"location":"#NeuroCore.jl-1","page":"Introduction","title":"NeuroCore.jl","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"NeuroCore ties together various packages throughout the Julia ecosystem and provides a set of common properties for developing tools related to computational neuroscience. It's aimed at easing the development of neuroscience related software that is compatible across a wide range of disciplines.","category":"page"},{"location":"working_with_interface/#Interfacing-With-NeuroCore-1","page":"Interfaceing With NeuroCore","title":"Interfacing With NeuroCore","text":"","category":"section"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"The most important component of the NeuroCore interface is just an array type that has a predictable way of identifying important features and is compatible with well established libraries for composing algorithms. Therefore, the easiest way to use data structures that are compatible with the NeuroCore interface is to just use already supported array types. This doesn't prevent developers from creating their own compatible array types or simply taking advantage of Julia's multiple dispatch to exclusively interface with those methods needed.","category":"page"},{"location":"working_with_interface/#Using-Existing-Array-Types-1","page":"Interfaceing With NeuroCore","title":"Using Existing Array Types","text":"","category":"section"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"The fully supported array types used in NeuroCore are derived from the AxisIndices package and are as follows...","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"AxisArray\nNamedAxisArray\nMetaAxisArray\nNamedMetaAxisArray","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"...and here's a quick guide to the prefixes.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Axis: supports fancy indexing\nNamed: supports named dimensions\nMeta: supports array level metadata ","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"The NamedMetaAxisArray type provides all the functionality that the other types do, so we'll be using it for most examples. Just be aware that the interface should be the same between each of these types where it makes sense (e.g., NamedAxisArray and NamedMetaAxisArray both use dimnames to return dimension names).","category":"page"},{"location":"working_with_interface/#From-IO-Streams-to-Arrays-1","page":"Interfaceing With NeuroCore","title":"From IO Streams to Arrays","text":"","category":"section"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"The only information necessary for composing a new NamedMetaAxisArray are the dimension names, axes, and metadata. For example, let's say we have a 2-dimensional image of the brain in the coronal view and it is read into memory by a special streaming type CoronalStream. We'll assume that we know the dimension names are \"sagittal\" and \"axial\", each axis is 50 millimeters long with 50 pixels, and we just want a simply Int type. We'll keep the metadata simple for know and only specify the institution name. Now let's use several different methods for composing our array.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"using NeuroCore\n\nusing Unitful: mm\n\nfunction NeuroCore.NamedMetaAxisArray(s::CoronalStream)\n    return NamedMetaAxisArray{(:sagittal, :axial)}(  # dimension names specified first as part of the type\n        read!(s, Array{Int}(undef, (50, 50))),       # Read a standard array in\n        (range(1, stop=50)mm, range(1, stop=50)mm),  # \n        institution_name = \"some institution\"        # metadata specified by key word\n    )\nend","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"We could make this a lot more composable by breaking it down to the core components that make up the type though.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"NeuroCore.dimnames(::Type{<:CoronalStream}) = (:sagittal, :axial)\n\nNeuroCore.axes(s::CoronalStream) = (range(1, stop=50)mm, range(1, stop=50)mm)\n\nNeuroCore.metadata(s::CoronalStream) = Dict{Symbol,Any}(institution_name => \"some institution\")\n\nBase.eltype(::Type{<:CoronalStream) = Int\n\nfunction NamedMetaAxisArray(x::CoronalStream)\n    T = eltype(x)\n    coronal_stream_axes = axes(x)\n    A = AxisArray{T}(undef, coronal_stream_axes)\n    read!(s, A)\n    return NamedMetaAxisArray{dimnames(s)}(A, metadata=metadata(s))\nend","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Note that the metadata is a reserved keyword for providing the collection of metadata Also note that metadata is expected to have a Symbol type as its keys. This allows metadata to be accessed like properties (e.g., array_instance.institution_name)","category":"page"},{"location":"working_with_interface/#Using-Other-Array-Like-Types-1","page":"Interfaceing With NeuroCore","title":"Using Other Array-Like Types","text":"","category":"section"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"If for some reason the structure you want to use is like an array but isn't a subtype of an array (i.e. so you cannot wrap it in a NamedMetaAxisArray), then you can piece together whatever functionality you need using something like the following.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"using AxisIndices\n\nusing NamedDims\n\nNamedDims.dimnames(::Type{<:MatrixType}) = (:dim1_name, :dim2_name)\n\nAxisIndices.metadata(x::MatrixType) = getfield(x, :metadata)\n\nBase.parent(x::MatrixType) = getfield(x, :parent)\n\nBase.@propagate_inbounds function Base.getindex(x::MatrixType, arg1::Int, arg2::Int)\n    return getindex(parent(x), arg1, arg2)\nend\n\nBase.@propagate_inbounds function Base.getindex(x::MatrixType, arg1, arg2)\n    return getindex(\n        x,\n        AxisIndices.to_index(axes(x, 1), arg1),\n        AxisIndices.to_index(axes(x, 2), arg2)\n    )\nend\n\nBase.@propagate_inbounds function Base.getindex(x::MatrixType; kwargs...)\n    inds = NamedDims.order_named_inds(x; kwargs...)\n    return getindex(x, inds...)\nend\n\nBase.getproperty(x::MatrixType, s::Symbol) = getproperty(metadata(x), s)\n\nBase.setproperty!(x::MatrixType, s::Symbol, val) = setproperty!(metadata(x), s, val)\n\nBase.propertynames(x::MatrixType) = propertynames(metadata(x))","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Let's run through this by each feature we're trying to support.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Named dimensions: We need to be able to extract this with dimnames. In order to get nice named indexing we have to provide a version of getindex that uses keyword arguments.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"This won't provide named dimension interfaces for other functions (e.g., permutedims, etc.).   Each of these must be overloaded individually for the new type.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Fancy indexing: accomplished through conversion of arguments at each axis via AxisIndices.to_index.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"This gets more involved if supporting arbitrary dimensions.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Metadata: Main component is AxisIndices.metadata.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"The last 3 lines allow metadata to be treated like properties.   Note that if you do this fields cannot be accessed like properties.   For example, we assume that MatrixType wraps a parent structure but this cannot be accessed via MatrixType.parent anymore.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"In addition to consulting the documentation for NamedDims or AxisIndices, users may be interested in Julia's documentation of the array interface.","category":"page"},{"location":"working_with_interface/#Overload-Important-Methods-1","page":"Interfaceing With NeuroCore","title":"Overload Important Methods","text":"","category":"section"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"Up to this point we've assumed that everything is an array or array-like. However, the same principles broadly apply to other data structures. For example, a structural connectome may be stored as an unordered collection of vectors of points. In this case the relation between the first and second fiber stored may have no spatial relationship. However, we can still use Base.axes, NamedDims.dimnames, etc. to provide information about the spatial orientation.","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"struct Fibers{L,Axs}\n    fibers::Vector{Vector{Point3f0}}\n    axes::NamedTuple{L,Axs}\nend\n\nNeuroCore.dimnames(::Type{<:Fibers{L,Axs}}) where {L,Axs} = L\n\nBase.axes(f::Fibers) = values(getfield(f, :axes))","category":"page"},{"location":"working_with_interface/#","page":"Interfaceing With NeuroCore","title":"Interfaceing With NeuroCore","text":"This alone provides compatibility with most methods in NeuroCore.SpatialAPI and NeuroCore.AnatomicalAPI.","category":"page"}]
}
